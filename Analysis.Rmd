---
title: "Analysis"
author: "Anita Kurm, Maris Sala"
date: "May 21, 2018"
output: pdf_document
---

Actual Bayesian computational modeling here

```{r}
#libraries 
pacman::p_load(dplyr,magrittr,rethinking,brms,brmstools,ggplot2,caret)
pacman::p_install_gh("mvuorre/brmstools")

#data
data = read.csv("CleanData.csv")
data$X = NULL

#new column
data$ID_new = as.factor(paste(data$fileID, data$runNumber, sep = "_"))

#arrange
df<-dplyr::arrange(data, ID_new)

#Summarize by so we know the ticks it took to complete each sim - our outcome
maxTick = dplyr::group_by(df,ID_new) %>%
  dplyr::summarize(maxTick = max(tick))
new_df=merge(df,maxTick, all = T)

```

So what do we want our models to do?  it's very trashy, fix later.. when we figure out the repeated measures thing


```{r}
rescalelist = c("outbreakSize","probDetect", "clusteringCoef","pathLength")
new_df.s = new_df[, colnames(new_df) %in% rescalelist] %>% 
  lapply(.,function(x) scale(x,center= mean(x,na.rm = T), scale = sd(x, na.rm = T)))%>% 
  cbind(.,new_df[,! colnames(new_df) %in% rescalelist]) 

new_df.s2 = unique(new_df.s$ID_new)
new_df.s2 = group_by(new_df.s, ID_new, outbreakSize, probDetect, maxTick,clusteringCoef, pathLength) %>%
  summarise_each(funs(mean(., na.rm = TRUE)), runNumber)

#ProbDetect model
m1_formula <- bf(maxTick ~ outbreakSize + probDetect)

#Look at the outcome function - which likelihood function do we want?
  #Outcome is count - poisson 
dens(new_df.s2$maxTick)
sd(new_df.s2$maxTick)

#get_prior(m1_formula,new_df) #Asking the model which priors it recommend

prior = c(prior(normal(log(80),log(133)), class = Intercept),
          prior(normal(0,0.5), class = b, coef = outbreakSize), 
          prior(normal(0,0.5), class = b, coef = probDetect)) 


m1 <- brm(m1_formula,
          family = poisson(link = "log"), #We assume our likelihood function to be poisson
          prior = prior, #our list of pre-defined priors
          data = new_df.s2,
          warmup = 500,
          iter = 1000,
          cores = 3,
          chain = 3)

summary(m1)
plot(m1)

m1 <- brm(
  bf(maxTick ~ beta * outbreakSize + (beta^2) * probDetect + mui,
     mui ~ 1 + (1|ID_new),
     beta~1,
     nl = TRUE),
          family = gaussian(), #We assume our likelihood function to be normally distributed
          prior = prior, #our list of pre-defined priors #write NULL here to use default priors
          data = new_df,
          iter = 2000,
          core = 1,
          chain = 1)

summary(m1)
plot(m1)

dens(new_df$maxTick) #looks binomial? 


m2_formula <- bf(maxTick ~ clusteringCoef + pathLength + outbreakSize + (1|ID_new)) #The last bit is how you add repeated measures
#We need to consider: Random effects?
#Remember: when comparing the models, this model should be punished because it's adding all them parameters 


get_prior(m2_formula,new_df) #Asking the model which priors it recommend

prior = c(prior(normal(0,1), class = Intercept),
          prior(normal(0,1), class = b, coef = clusteringCoef),
          prior(normal(0,1), class = b, coef = pathLength),
          prior(normal(0,1), class = b, coef = outbreakSize ),
          prior(cauchy(0,2), class = sigma))

m2 <- brm(m2_formula,
          family = gaussian(), #We assume our likelihood function to be normally distributed
          prior = NULL, #our list of pre-defined priors
          data = new_df,
          iter = 2000,
          cores = 2,
          chain = 2)

summary(m2)
plot(m2)

```

